{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5840765-49c2-4450-bbec-22f40ea0187a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 06:42:47.419530: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-16 06:42:47.423381: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-16 06:42:47.435308: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1739688167.454936    1804 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1739688167.460952    1804 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-16 06:42:47.482305: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data Loaded Successfully!\n",
      "      timestamp                   datetime can_id           payload  \\\n",
      "0  1.536574e+09 2018-09-10 10:06:04.242068    1C8  83FF0000FFFE3BFF   \n",
      "1  1.536574e+09 2018-09-10 10:06:04.242212    1E9  0000000E00010000   \n",
      "2  1.536574e+09 2018-09-10 10:06:04.242485    232  0000000000000000   \n",
      "3  1.536574e+09 2018-09-10 10:06:04.242641    348        000000001B   \n",
      "4  1.536574e+09 2018-09-10 10:06:04.242807    34A        000000001B   \n",
      "\n",
      "   payload_length  \n",
      "0              16  \n",
      "1              16  \n",
      "2              16  \n",
      "3              10  \n",
      "4              10  \n",
      "ğŸ¯ Random Forest Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/myfolder/.user-python-packages/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [06:43:20] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ XGBoost Accuracy: 1.0000\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 06:43:22.741393: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "/workspaces/myfolder/.user-python-packages/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m67252/67252\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 8.7700e-12\n",
      "Epoch 2/5\n",
      "\u001b[1m67252/67252\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.5635e-11 - val_accuracy: 1.0000 - val_loss: 3.0851e-12\n",
      "Epoch 3/5\n",
      "\u001b[1m67252/67252\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.1211e-11 - val_accuracy: 1.0000 - val_loss: 1.7925e-12\n",
      "Epoch 4/5\n",
      "\u001b[1m67252/67252\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.4422e-11 - val_accuracy: 1.0000 - val_loss: 1.2412e-12\n",
      "Epoch 5/5\n",
      "\u001b[1m67252/67252\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.0480e-11 - val_accuracy: 1.0000 - val_loss: 9.4489e-13\n",
      "\u001b[1m16813/16813\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.4360e-13\n",
      "ğŸ”¥ LSTM Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import bz2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "class CANBusML:\n",
    "    def __init__(self, window_size=10):\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def load_data(self, file_path):\n",
    "        \"\"\"Load and preprocess CAN bus data.\"\"\"\n",
    "        extracted_file_path = file_path.replace(\".bz2\", \"\")\n",
    "        \n",
    "        if file_path.endswith(\".bz2\"):\n",
    "            with bz2.BZ2File(file_path, \"rb\") as fr, open(extracted_file_path, \"wb\") as fw:\n",
    "                fw.write(fr.read())\n",
    "            file_path = extracted_file_path\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"Error: File '{file_path}' not found.\")\n",
    "\n",
    "        data = []\n",
    "        with open(file_path, \"r\") as file:\n",
    "            for line in file:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) < 3:\n",
    "                    continue  \n",
    "                try:\n",
    "                    timestamp = float(parts[0].strip(\"()\"))\n",
    "                    can_id, payload = parts[2].split(\"#\")\n",
    "\n",
    "                    data.append({\n",
    "                        \"timestamp\": timestamp,\n",
    "                        \"datetime\": datetime.fromtimestamp(timestamp),\n",
    "                        \"can_id\": can_id,\n",
    "                        \"payload\": payload,\n",
    "                        \"payload_length\": len(payload),\n",
    "                    })\n",
    "                except (ValueError, IndexError):\n",
    "                    continue  \n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        print(\"âœ… Data Loaded Successfully!\")\n",
    "        print(df.head())\n",
    "        return df\n",
    "\n",
    "    def preprocess_data(self, df):\n",
    "        \"\"\"Feature Engineering\"\"\"\n",
    "        df['traffic_type'] = np.where(df['payload_length'] > 50, 1, 0)  \n",
    "        df[\"time_diff\"] = df[\"timestamp\"].diff().fillna(0)  \n",
    "        df['rolling_payload'] = df['payload_length'].rolling(window=self.window_size, min_periods=1).mean()\n",
    "\n",
    "        label_encoder = LabelEncoder()\n",
    "        df['can_id'] = label_encoder.fit_transform(df['can_id'])  \n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        df[['payload_length', 'time_diff', 'rolling_payload']] = scaler.fit_transform(df[['payload_length', 'time_diff', 'rolling_payload']])\n",
    "\n",
    "        return df.dropna()\n",
    "\n",
    "    def split_data(self, df):\n",
    "        \"\"\"Train-Test Split\"\"\"\n",
    "        features = ['can_id', 'payload_length', 'time_diff', 'rolling_payload']\n",
    "        X = df[features]\n",
    "        y = df['traffic_type']\n",
    "\n",
    "        return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Random_Forest \n",
    "    \n",
    "    def train_random_forest(self, X_train, y_train, X_test, y_test):\n",
    "        \"\"\"Train Random Forest\"\"\"\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"ğŸ¯ Random Forest Accuracy: {accuracy:.4f}\")\n",
    "        return model\n",
    "# XGBoost \n",
    "\n",
    "    def train_xgboost(self, X_train, y_train, X_test, y_test):\n",
    "        \"\"\"Train XGBoost\"\"\"\n",
    "        model = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"ğŸš€ XGBoost Accuracy: {accuracy:.4f}\")\n",
    "        return model\n",
    "# Long Short-Term Memory (LSTM)\n",
    "    def train_lstm(self, X_train, y_train, X_test, y_test):\n",
    "        \"\"\"Train LSTM for sequence prediction\"\"\"\n",
    "        X_train = np.reshape(X_train.values, (X_train.shape[0], X_train.shape[1], 1))\n",
    "        X_test = np.reshape(X_test.values, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "        model = Sequential([\n",
    "            LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], 1)),\n",
    "            Dropout(0.2),\n",
    "            LSTM(50),\n",
    "            Dropout(0.2),\n",
    "            Dense(1, activation=\"sigmoid\")\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "        model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "        loss, accuracy = model.evaluate(X_test, y_test)\n",
    "        print(f\"ğŸ”¥ LSTM Accuracy: {accuracy:.4f}\")\n",
    "        return model\n",
    "\n",
    "# ğŸ Run Pipeline\n",
    "pipeline = CANBusML(window_size=10)\n",
    "file_path = \"/workspaces/myfolder/full_data_capture.log.bz2\"\n",
    "\n",
    "df = pipeline.load_data(file_path)\n",
    "df = pipeline.preprocess_data(df)\n",
    "X_train, X_test, y_train, y_test = pipeline.split_data(df)\n",
    "\n",
    "rf_model = pipeline.train_random_forest(X_train, y_train, X_test, y_test)\n",
    "xgb_model = pipeline.train_xgboost(X_train, y_train, X_test, y_test)\n",
    "lstm_model = pipeline.train_lstm(X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a47182-57d3-4c84-8723-d8bebd7ae05c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Workbench Python",
   "language": "python",
   "name": "workbench_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
